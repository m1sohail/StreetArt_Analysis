{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Comments Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQzsakkndCAD"
      },
      "source": [
        "# Comment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA7z0V2NdCAK"
      },
      "source": [
        "**Objective**: \n",
        "\n",
        "Get the most important topics using an LDA across hashtags by using an LDA analysis.     \n",
        "\n",
        "**Contents**: <br>\n",
        "**1. Data Import - Comments**<br>\n",
        "**2. Preprocessing - Cleaning and Tokenization**<br>\n",
        "**4. Data Transformation - Bigrams, Trigrams and Lemmatization**<br>\n",
        "**5. Topic modeling using LDA**<br>\n",
        "**6. Demo**<br>\n",
        "**7. Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIK_ejhYNJOe"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtPBVhcWQv_E",
        "outputId": "975791ba-7fce-434b-9125-ea6c8078bf1a"
      },
      "source": [
        "#pip install packages to perform topic analysis\n",
        "!pip install gensim\n",
        "!pip install pprint\n",
        "!pip install pyldavis\n",
        "!pip install pyLDAvis\n",
        "!pip install spacy\n",
        "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "#!pip install pandas==1.1.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\alfon\\anaconda3\\lib\\site-packages (3.8.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: Cython==0.29.14 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from gensim) (0.29.14)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from gensim) (3.0.0)\n",
            "Requirement already satisfied: requests in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement pprint\n",
            "ERROR: No matching distribution found for pprint\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyldavis in c:\\users\\alfon\\anaconda3\\lib\\site-packages (3.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (1.4.1)\n",
            "Requirement already satisfied: funcy in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (1.15)\n",
            "Requirement already satisfied: future in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (0.18.2)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (2.11.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (1.18.5)\n",
            "Requirement already satisfied: numexpr in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (2.7.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (0.17.0)\n",
            "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (1.1.3)\n",
            "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyldavis) (0.36.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyldavis) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyldavis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyldavis) (2020.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyldavis) (1.15.0)\n",
            "Requirement already satisfied: pyLDAvis in c:\\users\\alfon\\anaconda3\\lib\\site-packages (3.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.1.3)\n",
            "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.36.2)\n",
            "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: numexpr in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: funcy in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.15)\n",
            "Requirement already satisfied: future in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2020.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: spacy in c:\\users\\alfon\\anaconda3\\lib\\site-packages (3.0.3)\n",
            "Requirement already satisfied: pathy in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (8.0.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (53.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (1.7.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (3.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
            "Requirement already satisfied: six in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pathy->spacy) (3.0.0)\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz (12.0 MB)\n",
            "Requirement already satisfied: spacy>=2.2.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from en-core-web-sm==2.2.0) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (8.0.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.3.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (53.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.7.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.24.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.4.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.11.2)\n",
            "Requirement already satisfied: pathy in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (0.8.2)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.7.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (1.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (20.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (2.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy>=2.2.0->en-core-web-sm==2.2.0) (4.50.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.4.7)\n",
            "Requirement already satisfied: six in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (2.10)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy>=2.2.0->en-core-web-sm==2.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from jinja2->spacy>=2.2.0->en-core-web-sm==2.2.0) (1.1.1)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pathy->spacy>=2.2.0->en-core-web-sm==2.2.0) (3.0.0)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py): started\n",
            "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.0-py3-none-any.whl size=12019121 sha256=ad4bf0085bbd47e13fc42b666670a8182de8ab4f425c45be4776737283cb9724\n",
            "  Stored in directory: c:\\users\\alfon\\appdata\\local\\pip\\cache\\wheels\\fc\\31\\e9\\092e6f05b2817c9cb45804a3d1bf2b9bf6575742c01819337c\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.0.0\n",
            "    Uninstalling en-core-web-sm-3.0.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.0.0\n",
            "Successfully installed en-core-web-sm-2.2.0\n",
            "Requirement already satisfied: pip in c:\\users\\alfon\\anaconda3\\lib\\site-packages (21.0.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\alfon\\anaconda3\\lib\\site-packages (53.0.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-54.2.0-py3-none-any.whl (785 kB)\n",
            "Requirement already satisfied: wheel in c:\\users\\alfon\\anaconda3\\lib\\site-packages (0.36.2)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 53.0.0\n",
            "    Uninstalling setuptools-53.0.0:\n",
            "      Successfully uninstalled setuptools-53.0.0\n",
            "Successfully installed setuptools-54.2.0\n",
            "Requirement already satisfied: spacy in c:\\users\\alfon\\anaconda3\\lib\\site-packages (3.0.3)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.0.5-cp38-cp38-win_amd64.whl (11.8 MB)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
            "Collecting thinc<8.1.0,>=8.0.2\n",
            "  Downloading thinc-8.0.2-cp38-cp38-win_amd64.whl (1.0 MB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (1.7.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (54.2.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (3.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: six in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.1\n",
            "    Uninstalling thinc-8.0.1:\n",
            "      Successfully uninstalled thinc-8.0.1\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.0.3\n",
            "    Uninstalling spacy-3.0.3:\n",
            "      Successfully uninstalled spacy-3.0.3\n",
            "Successfully installed spacy-3.0.5 thinc-8.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/84/5c/e0de0816d380d86a7468fda02bf10d54a01836f567c0cc4231e967f1215f/spacy-3.0.5-cp38-cp38-win_amd64.whl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.24.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.50.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (54.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: six in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.6.20)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\alfon\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.0\n",
            "    Uninstalling en-core-web-sm-2.2.0:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.0\n",
            "Successfully installed en-core-web-sm-3.0.0\n",
            "[+] Download and installation successful\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-04 19:23:46.693660: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
            "2021-04-04 19:23:46.694839: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p-JdpGZNRlT",
        "outputId": "39abe352-2580-4015-9284-5d1737aba281"
      },
      "source": [
        "#Import libraries for data pre-processing and LDA analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import gensim.corpora as corpora\n",
        "import gensim as gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\alfon\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\alfon\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-DI_cmLNLiy"
      },
      "source": [
        "### 1. Data Import - Comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhUjYSUpdCAO"
      },
      "source": [
        "To perform our topic modelling we are using Instagram posts retrieved using the Instaloader API (code available in another notebook). For simplicty we import the data as csv, so we don't need to run the API several times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcfW1NWMNq-F",
        "outputId": "7cec3087-adc9-4e8e-851f-34453bf950b7"
      },
      "source": [
        "df = pd.read_csv('https://github.com/AlfonsoCabello/Social_Media_Analytics_042021/raw/main/instagram_loader_final.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username_ID</th>\n",
              "      <th>Caption</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Comments_Text</th>\n",
              "      <th>Hashtags_Caption</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Location</th>\n",
              "      <th>Mentions_Caption</th>\n",
              "      <th>Username</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>175509226</td>\n",
              "      <td>Happy Friday! I wore this colorful kimono romp...</td>\n",
              "      <td>27</td>\n",
              "      <td>['The cutest romper 😍', 'You’re in my neck of ...</td>\n",
              "      <td>['liketkit', 'ltkunder50', 'ltktravel', 'ltkcu...</td>\n",
              "      <td>46</td>\n",
              "      <td>PostLocation(id=216296668, name='Galveston, Te...</td>\n",
              "      <td>['pinklily', 'gapsmack87', 'shipleydonuts_galv...</td>\n",
              "      <td>pearlsandpigsblog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1599189434</td>\n",
              "      <td>#mrphotography #gainwithwestandmugweru #gainwi...</td>\n",
              "      <td>20</td>\n",
              "      <td>['😍😍😍', '👏👏👏', '❤️', '❤️❤️❤️', '🔥🔥🔥', '🙌🙌', '❤...</td>\n",
              "      <td>['mrphotography', 'gainwithwestandmugweru', 'g...</td>\n",
              "      <td>20</td>\n",
              "      <td>PostLocation(id=1760813094235018, name='Jhujha...</td>\n",
              "      <td>[]</td>\n",
              "      <td>sameer.choudhary6375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2491624</td>\n",
              "      <td>@antoniopelayo x @isaacpelayo \\n\\nEdition of 5...</td>\n",
              "      <td>18</td>\n",
              "      <td>['#isaacpelayo #antoniopelayo #dope #love #art...</td>\n",
              "      <td>[]</td>\n",
              "      <td>248</td>\n",
              "      <td>PostLocation(id=212999109, name='Los Angeles, ...</td>\n",
              "      <td>['antoniopelayo', 'isaacpelayo']</td>\n",
              "      <td>isaacpelayo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47338304181</td>\n",
              "      <td>#digitalcollage #digitalartwork #digitalcollag...</td>\n",
              "      <td>8</td>\n",
              "      <td>['🤩👌', '👏👏👏😍😍😍', 'Magnifique.👏👏👏👏👏', '🖤✨🤓✨🖤 Fa...</td>\n",
              "      <td>['digitalcollage', 'digitalartwork', 'digitalc...</td>\n",
              "      <td>90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>thedi0nys0s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40846095404</td>\n",
              "      <td>#gainwithwestandmugweru #gainwithmchina#gainwi...</td>\n",
              "      <td>8</td>\n",
              "      <td>['😘😘😘', '😍😍😍', '😍😍😍', '🔥🔥🔥', '😘😘😘', '❤️❤️❤️', ...</td>\n",
              "      <td>['gainwithwestandmugweru', 'gainwithmchina', '...</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>soyal_hamza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Username_ID                                            Caption  Comments  \\\n",
              "0    175509226  Happy Friday! I wore this colorful kimono romp...        27   \n",
              "1   1599189434  #mrphotography #gainwithwestandmugweru #gainwi...        20   \n",
              "2      2491624  @antoniopelayo x @isaacpelayo \\n\\nEdition of 5...        18   \n",
              "3  47338304181  #digitalcollage #digitalartwork #digitalcollag...         8   \n",
              "4  40846095404  #gainwithwestandmugweru #gainwithmchina#gainwi...         8   \n",
              "\n",
              "                                       Comments_Text  \\\n",
              "0  ['The cutest romper 😍', 'You’re in my neck of ...   \n",
              "1  ['😍😍😍', '👏👏👏', '❤️', '❤️❤️❤️', '🔥🔥🔥', '🙌🙌', '❤...   \n",
              "2  ['#isaacpelayo #antoniopelayo #dope #love #art...   \n",
              "3  ['🤩👌', '👏👏👏😍😍😍', 'Magnifique.👏👏👏👏👏', '🖤✨🤓✨🖤 Fa...   \n",
              "4  ['😘😘😘', '😍😍😍', '😍😍😍', '🔥🔥🔥', '😘😘😘', '❤️❤️❤️', ...   \n",
              "\n",
              "                                    Hashtags_Caption  Likes  \\\n",
              "0  ['liketkit', 'ltkunder50', 'ltktravel', 'ltkcu...     46   \n",
              "1  ['mrphotography', 'gainwithwestandmugweru', 'g...     20   \n",
              "2                                                 []    248   \n",
              "3  ['digitalcollage', 'digitalartwork', 'digitalc...     90   \n",
              "4  ['gainwithwestandmugweru', 'gainwithmchina', '...      8   \n",
              "\n",
              "                                            Location  \\\n",
              "0  PostLocation(id=216296668, name='Galveston, Te...   \n",
              "1  PostLocation(id=1760813094235018, name='Jhujha...   \n",
              "2  PostLocation(id=212999109, name='Los Angeles, ...   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                    Mentions_Caption              Username  \n",
              "0  ['pinklily', 'gapsmack87', 'shipleydonuts_galv...     pearlsandpigsblog  \n",
              "1                                                 []  sameer.choudhary6375  \n",
              "2                   ['antoniopelayo', 'isaacpelayo']           isaacpelayo  \n",
              "3                                                 []           thedi0nys0s  \n",
              "4                                                 []           soyal_hamza  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cz-p9cAOWO-"
      },
      "source": [
        "### 2. Preprocessing -  Cleaning and tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCS-crlhdCAP"
      },
      "source": [
        "In this step our goal is to prepare the data for the modeling and delete words or simbols that do not add value to the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uexXItuXOWdw"
      },
      "source": [
        "#Remove punctuations\n",
        "df['Comments_Text'] = np.array(list(x.translate(str.maketrans(\"\",\"\", (string.punctuation+'•`'))) for x in list(df['Comments_Text'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2q3GsOcOoym"
      },
      "source": [
        "#Comments to lowecase\n",
        "df['Comments_Text'] = np.array([x.lower() for x in list(df['Comments_Text'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7F1WzYKOrPi"
      },
      "source": [
        "#Delete whitespaces\n",
        "df['Comments_Text'] = np.array([x.strip() for x in list(df['Comments_Text'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sF4HGI-O8Gv"
      },
      "source": [
        "#Tokenize words\n",
        "df['Comments_Text'] = np.array([word_tokenize(x) for x in list(df['Comments_Text'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PSToaQ9PVGx"
      },
      "source": [
        "#Remove stopwords\n",
        "sw = set(stopwords.words('english'))\n",
        "df['Comments_Text'] = np.array([[i for i in x if i not in sw] for x in list(df['Comments_Text'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIE0blC7Pryw"
      },
      "source": [
        "#Replace numbers to words\n",
        "array = np.array([['0', 'zero'], ['1', 'one'], ['2', 'two'], ['3', 'three'], ['4', 'four'], ['5', 'five'], ['6', 'six'], ['7', 'seven'], ['8', 'eight'], ['9', 'nine'], ['10', 'ten'], ['12', 'twelve'], ['20', 'twenty']])\n",
        "nums = pd.DataFrame(array, columns = ['Number', 'Word'])\n",
        "\n",
        "#Loop each token, if it's a number change for a word\n",
        "for x in list(df['Comments_Text']):\n",
        "    for idx, number in enumerate(x):\n",
        "        if number in list(nums['Number']):\n",
        "            x[idx] = nums[nums['Number'] == number]['Word'].to_list()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhmBGwxtQQGU"
      },
      "source": [
        "#Remove websites, hashtags and years\n",
        "for toke in list(df['Comments_Text']):\n",
        "    for idx, i in enumerate(toke):\n",
        "        toke[idx] = re.sub(r'\\d+', '', i)\n",
        "        toke[idx] = re.sub(r'www', '', i)\n",
        "        toke[idx] = re.sub(r'#', '', i)\n",
        "        toke[idx] = re.sub(r'com', '', i)\n",
        "    toke = list(filter(lambda x: x != '', toke))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRM0bx96QbCR",
        "outputId": "6041916a-e6ae-4560-e544-34a86fc75c6e"
      },
      "source": [
        "#Comments to be analized\n",
        "#We analyze posts that have comments (at least 1)\n",
        "\n",
        "data_words = df[df['Comments_Text'].map(lambda d: len(d)) > 0]\n",
        "data_words = data_words['Comments_Text']\n",
        "data_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [cutest, romper, 😍, ’, neck, woods, romper, pe...\n",
              "1      [😍😍😍, 👏👏👏, ❤️, ❤️❤️❤️, 🔥🔥🔥, 🙌🙌, ❤️❤️, 🙌, 🔥🔥🔥, ...\n",
              "2      [isaacpelayo, antoniopelayo, dope, love, art, ...\n",
              "3      [🤩👌, 👏👏👏😍😍😍, magnifique👏👏👏👏👏, 🖤✨🤓✨🖤, fantástic...\n",
              "4      [😘😘😘, 😍😍😍, 😍😍😍, 🔥🔥🔥, 😘😘😘, ❤️❤️❤️, ❤️❤️❤️, 🔥🔥🔥,...\n",
              "                             ...                        \n",
              "219                                         [❤️❤️❤️❤️❤️]\n",
              "220                                     [art, 🤍🤍🤍🤍🤍🤍🤍🤍💙]\n",
              "221                                  [brilliant, ❤️❤️❤️]\n",
              "222    [unfortunately, two, photos, didnt, load, next...\n",
              "223                                         [👏👏👏💚🍀💚🍀💚🍀🤍]\n",
              "Name: Comments_Text, Length: 223, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6KG0M3gQ4Gg"
      },
      "source": [
        "### 3. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szxDjYc1dCAS"
      },
      "source": [
        "To fit the data into the LDA model we need to take some preprocessing steps such as bigrams and lemmatization that significantly improves the performance of the topic modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjyz0H0xRBh7",
        "outputId": "b73ee7ec-d6e4-4308-912e-acd9d726d049"
      },
      "source": [
        "#Next we create a dictionary with the text to be analized\n",
        "import gensim.corpora as corpora\n",
        "import gensim as gensim\n",
        "\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "texts = data_words\n",
        "\n",
        "#Determine frequency of the words\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(corpus[:1][0][:30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 3), (8, 2), (9, 2), (10, 1), (11, 2), (12, 3), (13, 1), (14, 2), (15, 1), (16, 5), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1), (29, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX8G5jzZR9NM"
      },
      "source": [
        "Bigrams are two words frequently occurring together in the comment. Trigrams are 3 words frequently occurring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "684t-zPmR5WE"
      },
      "source": [
        "#Define bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=200) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=200)\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7gVaSIWSIC-"
      },
      "source": [
        "#Functions that create the bigrams abd trigams and loop through each word in the text to be analized \n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxJXTGESOc9",
        "outputId": "7cbc7666-7845-4c29-a37b-61f3e486ac5b"
      },
      "source": [
        "##Important to import the en_core_web_sm##\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "#Fit bigrams\n",
        "data_words_bigrams = make_bigrams(data_words)\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "#lemmatize dataset that has been processed with bigrams\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['cut', 'romper', '😍', 'neck', 'wood', 'romper', 'perfect', 'beach', 'vacation', 'cut', 'romper', 'perfect', 'tropical', 'vacay', 'romper', 'cute', 'love', '❤', '️', '❤', '️', '❤', '️', '❤', '️', '❤', '️', '❤', '️', 'affordablefashion', 'momstyle', 'outfitinspiration', 'outfitidea', 'onlineshopping', 'styleblogg', 'stylish', 'ootdinspo', 'outfitdetail', 'effortlessstyle', 'galvestontx', 'beachstyle', 'vacationstyle', 'beachvacation', 'muralart', 'pinklilyboutique', 'romperseason', 'romperstyle', 'springstyle', 'lifestyleblogger', 'cute', '😍', 'thank', 'love', 'love', 'fun', 'print', '❤', '️', 'love', 'mural', 'background', 'fun', 'romper', 'cute', 'fun', 'wall', 'happy', 'friday', 'love', 'romper', 'happy', 'friday', 'well', 'pretty', 'sweet', '✨', 'dm', 'aphroditetreasure', 'sweetie', 'crescendojewel', '💙']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT_JmO-OSZ-H",
        "outputId": "73cade16-f189-4906-fe5f-c6b47bf71a23"
      },
      "source": [
        "import gensim.corpora as corpora\n",
        "\n",
        "#Next we create a new dictionary with the transformed text\n",
        "#These are the main inputs for the LDA\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "#Create Corpus\n",
        "texts = data_lemmatized\n",
        "#Term Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(corpus[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 3), (9, 1), (10, 1), (11, 2), (12, 3), (13, 1), (14, 2), (15, 1), (16, 5), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 6), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 7), (48, 7), (49, 1), (50, 2)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxrxvsGNdCAU"
      },
      "source": [
        "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
        "For example, (16, 5) above implies, word id 16 occurs five times in the first comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC2a4A7wQr3N"
      },
      "source": [
        "### 4. Topic Modelling Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlm4zKbmdCAV"
      },
      "source": [
        "Initially we are creating a model with 3 topics to measure how coherent are our topics, then we are doing a grid search to find the optimal topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXkQ49LSd4J"
      },
      "source": [
        "#### 4.1. Initial Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY7Y4EELSgIk"
      },
      "source": [
        "#Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=3, \n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLqiUKivSkn5",
        "outputId": "64ab961e-d0ac-406f-e071-f8f76ec57234"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the keywords in the 10 topics and its weights\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.038*\"😍\" + 0.018*\"👏\" + 0.015*\"promote\" + 0.009*\"virtuosoig\" + 0.007*\"art\" '\n",
            "  '+ 0.006*\"muralart\" + 0.006*\"mural\" + 0.005*\"dm\" + 0.005*\"streetart\" + '\n",
            "  '0.005*\"👌\"'),\n",
            " (1,\n",
            "  '0.044*\"🔥\" + 0.016*\"art\" + 0.013*\"mural\" + 0.012*\"love\" + 0.007*\"muralart\" + '\n",
            "  '0.007*\"urbanart\" + 0.006*\"😍\" + 0.006*\"artist\" + 0.006*\"artwork\" + '\n",
            "  '0.006*\"paint\"'),\n",
            " (2,\n",
            "  '0.090*\"❤\" + 0.082*\"️\" + 0.030*\"🔥\" + 0.011*\"dm\" + 0.009*\"😍\" + 0.008*\"love\" + '\n",
            "  '0.006*\"amazing\" + 0.006*\"romper\" + 0.005*\"virtuosoig\" + 0.005*\"mural\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU9YCgAhSvfz",
        "outputId": "9e62009b-c2d6-4407-f3ae-ce6d3461d1a3"
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "#Get Coherance score\n",
        "\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score:  0.49117982022828954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC3NTKokSxeo"
      },
      "source": [
        "From the previous analysis we got a cohereance score of .49 which means that are our model is achievieng to represent the main topics but still needs fune tunning to perform better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4zc6vSQTLeY"
      },
      "source": [
        "####  4.2. Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuyaVOOiTJ_K"
      },
      "source": [
        "#Model to be used in the grid search to find best parameters \n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS7krjNLTRCP",
        "outputId": "0cd62a08-aea8-424b-db00-54cc1ecb71d8"
      },
      "source": [
        "#Grid serach\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "\n",
        "# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 11\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
        "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
        "               gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
        "               corpus]\n",
        "corpus_title = ['75% Corpus', '100% Corpus']\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=540)\n",
        "    \n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "                    \n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results)\n",
        "    pbar.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/540 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n",
            "100%|██████████| 540/540 [12:41<00:00,  1.41s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SFRGzHPan83"
      },
      "source": [
        "results = pd.DataFrame(model_results)\n",
        "results.to_csv('results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCynyJdwThR_"
      },
      "source": [
        "Best parameters:\n",
        "Topics = 3 \n",
        "Alpha = 0.01\n",
        "Beta = 0.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LIY3lkhTh2r"
      },
      "source": [
        "#### 4.3.  Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umpwMe9GTiCp"
      },
      "source": [
        "#Final optimized model\n",
        "\n",
        "k = 3\n",
        "alpha= .01\n",
        "beta = .31\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=alpha,\n",
        "                                           eta=beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRmWn192TogP",
        "outputId": "6f66d146-b731-4702-a1e8-a5e5a426f92b"
      },
      "source": [
        "#Get Coherence score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.5009183892327541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awXgRgE8Ts5u"
      },
      "source": [
        "#### 4.4. Words in Topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWUVVlJzdCAa"
      },
      "source": [
        "From the model above we have come up with 5 topics that describe the comments gathered. Next we are analizing each topic and comparing its coherence score to determine which topics are semantically interpretable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMwXlsu8TrBr",
        "outputId": "a869cc91-0ada-4b79-d29c-092593f97a93"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the keywords in the topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.034*\"😍\" + 0.019*\"👏\" + 0.008*\"mural\" + 0.008*\"️\" + 0.007*\"muralart\" + '\n",
            "  '0.006*\"streetart\" + 0.005*\"promote\" + 0.005*\"👌\" + 0.005*\"que\" + 0.005*\"❤\"'),\n",
            " (1,\n",
            "  '0.042*\"🔥\" + 0.019*\"art\" + 0.013*\"love\" + 0.011*\"😍\" + 0.010*\"mural\" + '\n",
            "  '0.010*\"virtuosoig\" + 0.010*\"promote\" + 0.009*\"❤\" + 0.006*\"urbanart\" + '\n",
            "  '0.006*\"muralart\"'),\n",
            " (2,\n",
            "  '0.085*\"❤\" + 0.079*\"️\" + 0.030*\"🔥\" + 0.011*\"dm\" + 0.009*\"😍\" + 0.009*\"love\" + '\n",
            "  '0.006*\"mural\" + 0.006*\"romper\" + 0.005*\"amazing\" + 0.005*\"art\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjvegoBPTyno"
      },
      "source": [
        "#Get each topic and extract the words into a dataframe\n",
        "top_words_per_topic = []\n",
        "for t in range(lda_model.num_topics):\n",
        "    top_words_per_topic.extend([(t, ) + x for x in lda_model.show_topic(t, topn = 10)])\n",
        "    \n",
        "finalData = pd.DataFrame(top_words_per_topic, columns=['Topic', 'Word', 'CoheranceScore'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHhq8JVoT6eu"
      },
      "source": [
        "#### 4.5. Topics Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VN1qKuFdCAb"
      },
      "source": [
        "From the analysis, we got that the most coherent topic is topic #3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHWqmNHET6n4",
        "outputId": "b7a1a24d-f2d0-4400-d52b-2f1714d04d20"
      },
      "source": [
        "#Get each topic importance\n",
        "finalData_topics = pd.DataFrame(finalData.groupby('Topic')['CoheranceScore'].mean())\n",
        "\n",
        "#Determine the topic with the highest score\n",
        "highSC = pd.DataFrame(finalData_topics.loc[finalData_topics['CoheranceScore'].idxmax()]).columns[0]\n",
        "finalData_topics\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CoheranceScore</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.013610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.024468</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CoheranceScore\n",
              "Topic                \n",
              "0            0.010331\n",
              "1            0.013610\n",
              "2            0.024468"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXBOZtBaUCoS"
      },
      "source": [
        "#### 4.6. Most Important Words in Topic 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "68LnrUmGUInJ",
        "outputId": "603aca18-b53c-4a82-d90b-3340406375d2"
      },
      "source": [
        "#Get words\n",
        "finalData_words = finalData[(finalData.Topic==highSC)]\n",
        "finalData_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Word</th>\n",
              "      <th>CoheranceScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2</td>\n",
              "      <td>❤</td>\n",
              "      <td>0.085328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>️</td>\n",
              "      <td>0.078904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>🔥</td>\n",
              "      <td>0.030348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>dm</td>\n",
              "      <td>0.010654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>😍</td>\n",
              "      <td>0.009091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>love</td>\n",
              "      <td>0.008549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>mural</td>\n",
              "      <td>0.005804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2</td>\n",
              "      <td>romper</td>\n",
              "      <td>0.005799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2</td>\n",
              "      <td>amazing</td>\n",
              "      <td>0.005315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2</td>\n",
              "      <td>art</td>\n",
              "      <td>0.004893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Topic     Word  CoheranceScore\n",
              "20      2        ❤        0.085328\n",
              "21      2        ️        0.078904\n",
              "22      2        🔥        0.030348\n",
              "23      2       dm        0.010654\n",
              "24      2        😍        0.009091\n",
              "25      2     love        0.008549\n",
              "26      2    mural        0.005804\n",
              "27      2   romper        0.005799\n",
              "28      2  amazing        0.005315\n",
              "29      2      art        0.004893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "CLGykBUNsgXZ",
        "outputId": "6be7de8b-2e5e-44c2-9700-35aa0566cce8"
      },
      "source": [
        "import pyLDAvis.gensim\n",
        "import pickle \n",
        "import pyLDAvis\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "LDAvis_prepared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el848424740223480489464137224\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el848424740223480489464137224_data = {\"mdsDat\": {\"x\": [0.01616840948102499, -0.10729341901930893, 0.09112500953828397], \"y\": [-0.10610781903941789, 0.040084388393274106, 0.06602343064614391], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [36.04379801327975, 33.96241694273467, 29.993785043985575]}, \"tinfo\": {\"Term\": [\"\\u2764\", \"\\ufe0f\", \"\\ud83d\\udd25\", \"\\ud83d\\udc4f\", \"\\ud83d\\ude0d\", \"art\", \"romper\", \"\\ud83d\\ude18\", \"cool\", \"virtuosoig\", \"promote\", \"\\ud83d\\udc4c\", \"dm\", \"artwork\", \"muralart\", \"shoutout\", \"\\u2728\", \"good\", \"go\", \"direct\", \"\\ud83c\\udf40\", \"love\", \"\\ud83d\\ude02\", \"\\ud83d\\udcaf\", \"pic\", \"fun\", \"cute\", \"\\ud83d\\ude2e\", \"send\", \"nice\", \"buen\", \"foodie\", \"\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\", \"style\", \"dude\", \"letter\", \"publicart\", \"\\ud83d\\ude1a\", \"appreciate\", \"isaacpelayo\", \"\\ud83d\\udc8e\", \"back\", \"artwork\", \"houstonartist\", \"walk\", \"collab\", \"visit\", \"fineart\", \"take\", \"tag\", \"thaicuisine\", \"yesss\", \"aerosolart\", \"make\", \"really\", \"artsy\", \"artistsoninstagram\", \"color\", \"pdx\", \"portland\", \"good\", \"go\", \"art\", \"virtuosoig\", \"\\ud83d\\udd25\", \"nice\", \"promote\", \"love\", \"artist\", \"paint\", \"urbanart\", \"mural\", \"\\ud83d\\udd1d\", \"\\ud83d\\udc99\", \"painting\", \"muralart\", \"draw\", \"look\", \"\\ud83d\\ude0d\", \"follow\", \"beautiful\", \"\\u2764\", \"\\ufe0f\", \"que\", \"contemporaryart\", \"romper\", \"\\ud83d\\ude18\", \"cool\", \"shoutout\", \"\\ufe0f\", \"\\u2764\", \"\\ud83d\\udcaf\", \"pic\", \"fun\", \"cute\", \"modern\", \"vous\", \"\\ud83e\\udd93\", \"brilliant\", \"gorgeous\", \"\\ud83d\\udc9d\", \"newandabstract\", \"post\", \"laart\", \"o\", \"gymrockstar\", \"con\", \"series\", \"nunca\", \"cut\", \"militarystroong\", \"ai\", \"\\ud83d\\ude02\", \"\\ud83d\\ude2e\", \"worldshot\", \"dm\", \"\\ud83d\\udd25\", \"amazing\", \"love\", \"abstract\", \"send\", \"\\ud83d\\ude0d\", \"look\", \"mural\", \"contemporaryart\", \"streetart\", \"beautiful\", \"art\", \"photo\", \"urbanart\", \"virtuosoig\", \"follow\", \"\\ud83d\\udc4f\", \"direct\", \"\\ud83c\\udf40\", \"\\ud83d\\udc4f\", \"trashkitten\", \"paintbig\", \"momblogger\", \"estou\", \"london\", \"algun\", \"jjurbanart\", \"detroitmural\", \"\\ud83d\\udc4d\", \"cityofbrotherlylove\", \"\\ud83d\\udc9a\", \"project\", \"londonart\", \"\\u05d7\\u05de\\u05d5\\u05d3\\u05d4\", \"\\u015bwi\\u0105t\", \"streetartdaily\", \"chama\", \"toddlermom\", \"show\", \"isso\", \"detroitusa\", \"car\", \"\\ud83d\\udc4c\", \"tasty\", \"\\u2728\", \"uma\", \"vai\", \"wele\", \"travel\", \"\\ud83d\\ude0d\", \"artlover\", \"muralart\", \"que\", \"streetart\", \"mural\", \"promote\", \"photo\", \"dm\", \"\\ufe0f\", \"send\", \"art\", \"beautiful\", \"\\ud83d\\udd25\", \"urbanart\", \"\\u2764\", \"love\", \"paint\", \"arte\", \"wallart\"], \"Freq\": [71.0, 65.0, 57.0, 15.0, 36.0, 20.0, 4.0, 3.0, 3.0, 10.0, 11.0, 4.0, 12.0, 5.0, 10.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 18.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.2216826551955564, 2.221682299202652, 2.2216815872168425, 2.2216815872168425, 2.221681231223938, 2.2191834070085754, 2.2188605214440726, 2.2186440777580554, 2.210686212367873, 2.2080851502101666, 2.2023394247293786, 2.124305958030119, 4.229150851942626, 1.5504487776931541, 1.5504484217002497, 1.5504484217002497, 1.5504482437037972, 1.550448065707345, 1.5504478877108927, 1.5504478877108927, 1.5504478877108927, 1.5504473537215357, 1.550446997728631, 1.5504466417357263, 1.5504462857428218, 1.5498204502164756, 1.5490835449038838, 1.5489941906848208, 1.5482681431558203, 1.5481803909048282, 3.5641486302358376, 3.564145426299696, 14.285593702954813, 7.501500998072818, 32.17528235596732, 2.8897531797473834, 7.483997538937787, 10.154306012481806, 4.223075477032148, 4.2184304816124865, 4.904612145187554, 7.590725635718596, 2.8929149307298876, 2.894417576780347, 2.891766853612444, 4.903321670908257, 2.212520287812546, 3.575142759109641, 8.259507434093882, 2.870926494985829, 3.232522015952676, 6.786202318834854, 3.6680063562265843, 2.221680697234581, 2.221677315301987, 4.176963384127882, 3.5207084406796705, 3.509971812273322, 2.844166341332435, 56.83770890248132, 61.46555264928611, 2.1952448625972267, 2.192810605150811, 2.1882317390529336, 2.1870637516713134, 1.531999772955567, 1.5319994375197883, 1.5319992698018987, 1.53199893436612, 1.5319987666482306, 1.5319985989303413, 1.5319982634945626, 1.5319977603408945, 1.531997592623005, 1.5310385817315482, 1.5305486777766784, 1.5302212924566148, 1.5294152402802696, 1.529359725658886, 1.527029956457552, 1.5211328277491727, 1.440778180641387, 2.8443917541757577, 2.825757625794432, 0.8687509096613962, 7.674752504352648, 21.860683795414396, 3.8284929064475897, 6.158258753423639, 2.1952443594435587, 2.3330866611857113, 6.54863555837941, 2.847623342468271, 4.180708860033445, 2.1952436885720013, 2.8614221640988617, 2.5229163093801166, 3.524808472203377, 1.9263144262360168, 2.1972110194143917, 2.2515878426365967, 1.8468993347445204, 1.5428601771642756, 2.0792203291329203, 2.0792195885356994, 12.036419473739427, 1.4510328797949563, 1.4510318429588467, 1.4510318429588467, 1.4510315467199582, 1.451031398600514, 1.4510312504810698, 1.4510312504810698, 1.4510312504810698, 1.4510311023616256, 1.451030806122737, 1.451030806122737, 1.451030658003293, 1.451030658003293, 1.4510305098838487, 1.4510303617644045, 1.4510303617644045, 1.4510302136449602, 1.4510302136449602, 1.451030065525516, 1.451029473047739, 1.4510290286894065, 1.443299859851004, 3.3352126352844227, 1.406940683638894, 2.7081620026808637, 0.8228387650820022, 0.8228387650820022, 2.0792209216106974, 2.0792197366551433, 21.8301020097774, 2.0792218103273625, 4.597522383851445, 3.253953123228574, 3.968601298906249, 5.224950128559994, 3.3664602094764247, 2.0756617594854823, 2.962273351277349, 4.879942913105453, 1.9486604450232692, 2.7215783656996217, 2.07921751486348, 3.1626383745822584, 2.0792164780273708, 3.2321733439112545, 2.2091233035074462, 1.4668961760322645, 1.4558509090766156, 1.4525961324092773], \"Total\": [71.0, 65.0, 57.0, 15.0, 36.0, 20.0, 4.0, 3.0, 3.0, 10.0, 11.0, 4.0, 12.0, 5.0, 10.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 18.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 2.62202735965656, 2.6220270036636557, 2.6220262916778463, 2.6220262916778463, 2.622025935684942, 2.6218659176875994, 2.62184451073688, 2.62183002791306, 2.621317812230108, 2.6211507413545134, 2.6207774932649697, 2.618260490597138, 5.263631750404071, 1.9507934821541582, 1.9507931261612537, 1.9507931261612537, 1.9507929481648012, 1.950792770168349, 1.9507925921718967, 1.9507925921718967, 1.9507925921718967, 1.9507920581825398, 1.950791702189635, 1.9507913461967303, 1.9507909902038258, 1.9507834257119312, 1.9507050760039442, 1.9506988538229508, 1.9506504712661974, 1.950645925112997, 4.592590560778344, 4.592588615857478, 20.53198054085781, 10.606800289670092, 57.19860452596397, 3.9213031574910135, 11.792882179201122, 18.521688069412892, 6.589626560001004, 7.217326095164539, 9.181039642629317, 16.996384624312036, 4.549550753806182, 4.584481678691742, 4.584646276863586, 10.366981416550939, 3.284579336751721, 7.245603533584916, 36.63824500225069, 5.263004698555368, 7.834655840196273, 71.48392831203222, 65.38565817181336, 6.43058451339501, 4.61165980266477, 4.587678569586453, 3.924564102020149, 3.924690241105794, 3.2606037995755583, 65.38565817181336, 71.48392831203222, 2.598066275551518, 2.5979352014030352, 2.597979337184303, 2.598008941608737, 1.9348211859098585, 1.9348208504740798, 1.9348206827561902, 1.9348203473204115, 1.9348201796025222, 1.9348200118846328, 1.934819676448854, 1.934819173295186, 1.9348190055772965, 1.9348321890588378, 1.9347409917320377, 1.9348419825491512, 1.9348501528943731, 1.934852019879305, 1.9347708712870115, 1.9342402288730995, 1.9358628976771832, 3.8895727496032126, 3.93254706069028, 1.2715723226156876, 12.410731845538692, 57.19860452596397, 7.190754806459305, 18.521688069412892, 3.9402451658820348, 4.48982972037249, 36.63824500225069, 7.245603533584916, 16.996384624312036, 4.61165980266477, 9.043585564053068, 7.834655840196273, 20.53198054085781, 4.485950141539114, 9.181039642629317, 10.606800289670092, 5.263004698555368, 15.218955558192967, 2.492908848966652, 2.492908108369431, 15.218955558192967, 1.8647213996286882, 1.8647203627925784, 1.8647203627925784, 1.8647200665536898, 1.864719918434246, 1.8647197703148017, 1.8647197703148017, 1.8647197703148017, 1.8647196221953575, 1.864719325956469, 1.864719325956469, 1.8647191778370247, 1.8647191778370247, 1.8647190297175804, 1.8647188815981361, 1.8647188815981361, 1.8647187334786919, 1.8647187334786919, 1.8647185853592476, 1.864717992881471, 1.8647175485231382, 1.8651464084361238, 4.412450359222727, 1.8676041137062294, 3.784213781378677, 1.2365272849157338, 1.2365272849157338, 3.156053187551433, 3.1640275395603092, 36.63824500225069, 3.1640357633249225, 10.366981416550939, 6.43058451339501, 9.043585564053068, 16.996384624312036, 11.792882179201122, 4.485950141539114, 12.410731845538692, 65.38565817181336, 4.48982972037249, 20.53198054085781, 7.834655840196273, 57.19860452596397, 9.181039642629317, 71.48392831203222, 18.521688069412892, 7.217326095164539, 4.541129643651216, 3.198879843320901], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.8409, -5.8409, -5.8409, -5.8409, -5.8409, -5.8421, -5.8422, -5.8423, -5.8459, -5.8471, -5.8497, -5.8858, -5.1972, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2007, -6.2011, -6.2015, -6.2016, -6.2021, -6.2021, -5.3683, -5.3683, -3.98, -4.6241, -3.168, -5.578, -4.6264, -4.3213, -5.1986, -5.1997, -5.049, -4.6123, -5.5769, -5.5764, -5.5773, -5.0493, -5.8451, -5.3652, -4.5278, -5.5846, -5.4659, -4.7243, -5.3396, -5.8409, -5.8409, -5.1501, -5.3211, -5.3241, -5.5345, -2.5395, -2.4613, -5.7934, -5.7945, -5.7966, -5.7972, -6.1532, -6.1532, -6.1532, -6.1532, -6.1532, -6.1532, -6.1532, -6.1532, -6.1532, -6.1538, -6.1541, -6.1543, -6.1548, -6.1549, -6.1564, -6.1603, -6.2145, -5.5344, -5.541, -6.7204, -4.5418, -3.495, -5.2373, -4.7619, -5.7934, -5.7325, -4.7005, -5.5332, -5.1492, -5.7934, -5.5284, -5.6543, -5.3199, -5.9241, -5.7925, -5.7681, -5.9662, -6.1461, -5.7235, -5.7235, -3.9675, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0832, -6.0885, -5.2509, -6.114, -5.4592, -6.6505, -6.6505, -5.7235, -5.7235, -3.3722, -5.7235, -4.9299, -5.2756, -5.077, -4.802, -5.2416, -5.7252, -5.3695, -4.8703, -5.7883, -5.4543, -5.7235, -5.3041, -5.7235, -5.2823, -5.6629, -6.0723, -6.0799, -6.0821], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8548, 0.8548, 0.8548, 0.8548, 0.8548, 0.8537, 0.8536, 0.8535, 0.8501, 0.8489, 0.8465, 0.8114, 0.8016, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7907, 0.7903, 0.7899, 0.7899, 0.7894, 0.7894, 0.7669, 0.7669, 0.6577, 0.674, 0.4451, 0.7152, 0.5657, 0.4194, 0.5755, 0.4834, 0.3935, 0.2144, 0.5677, 0.5605, 0.5596, 0.2717, 0.6253, 0.314, -0.4693, 0.4144, 0.1351, -1.3341, -1.8602, -0.0424, 0.2901, 0.9861, 0.9713, 0.9682, 0.9433, 0.9398, 0.9289, 0.9114, 0.9104, 0.9083, 0.9077, 0.8465, 0.8465, 0.8465, 0.8465, 0.8465, 0.8465, 0.8465, 0.8465, 0.8465, 0.8458, 0.8456, 0.8453, 0.8448, 0.8447, 0.8433, 0.8397, 0.7845, 0.767, 0.7494, 0.699, 0.5993, 0.1181, 0.4496, -0.0212, 0.495, 0.4253, -0.6419, 0.146, -0.3226, 0.3376, -0.0708, -0.0532, -0.6822, 0.2346, -0.35, -0.4699, 0.0327, -1.209, 1.0227, 1.0227, 0.9696, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9533, 0.9478, 0.9243, 0.9209, 0.8696, 0.7969, 0.7969, 0.7869, 0.7843, 0.6864, 0.7843, 0.3911, 0.523, 0.3805, 0.0246, -0.0495, 0.4335, -0.2284, -1.391, 0.3695, -0.8166, -0.1224, -1.6909, -0.281, -1.8921, -0.9222, -0.3892, 0.0666, 0.4147]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 1, 3, 1, 1, 2, 3, 2, 1, 3, 3, 3, 1, 1, 2, 1, 2, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 1, 3, 1, 1, 2, 3, 1, 2, 1, 3, 1, 3, 2, 2, 1, 1, 3, 3, 2, 1, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 2, 2, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 2, 3, 2, 2, 3, 1, 2, 3, 3, 1, 1, 1, 3, 1, 3, 3, 1, 3, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 1, 1, 2, 3, 2, 3, 2, 1, 3, 3, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 3, 1, 2, 3, 1, 1, 2, 3, 3, 2, 2, 1, 3, 1, 2, 3, 2, 3, 1, 2, 3, 2, 1, 1, 2, 1, 2], \"Freq\": [0.5075826289484945, 0.5075826289484945, 1.0252247832278207, 0.5165655074023512, 0.5362736084635281, 0.278134918215184, 0.556269836430368, 0.139067459107592, 0.762975016104012, 0.681863104834946, 0.19481802995284173, 0.1461135224646313, 0.4404190492108336, 0.2202095246054168, 0.2202095246054168, 0.6070146712531447, 0.30350733562657234, 0.15175366781328617, 1.0252703110287884, 0.3160520533905569, 0.6321041067811138, 1.0252291328906014, 0.7599315814015549, 0.18998289535038873, 0.7638659358694546, 0.382914075766836, 0.382914075766836, 0.255276050511224, 1.033687702721267, 0.7627685472595394, 0.5361509399353125, 0.5362739066467511, 0.5362737362562974, 1.0252240348701531, 1.0252735813528724, 1.0336761441184996, 0.4336833343266851, 0.4336833343266851, 1.0191887140812894, 1.0337141362220312, 0.7698202912117622, 0.5362736084635281, 0.5362742474279834, 0.8022756230453552, 0.16115085112558802, 0.6446034045023521, 0.24172627668838204, 0.6089059800205333, 0.30445299001026666, 0.7627689615043978, 0.5362735232683825, 1.0252242219594676, 0.5700165916293908, 0.38001106108626054, 0.19000553054313027, 0.7627686508207118, 0.7698290634472887, 0.8709684961088472, 0.2177421240272118, 0.8709681272615095, 0.21774203181537738, 1.033687792325418, 1.0337301005906432, 1.025223847780907, 0.7630236477610877, 0.5362741196349705, 0.5362736084635281, 1.033688419554911, 0.7628155149001422, 0.5362735658659519, 0.5362737788539006, 0.5520589115122223, 0.4140441836341667, 0.13801472787805558, 0.5399075917121298, 0.3239445550272778, 0.10798151834242595, 1.0252249703174083, 1.0339977269344731, 1.0336872547007443, 0.5362734380732639, 0.4706883361863092, 0.2353441680931546, 0.29418021011644324, 0.48230046906590135, 0.09646009381318027, 0.48230046906590135, 1.0336880611379646, 0.7650517900583602, 0.25501726335278674, 1.0336707817710828, 1.0336813762504447, 0.5542218748685774, 0.2771109374342887, 0.13855546871714436, 0.5362734380732639, 0.6543580068847401, 0.21811933562824667, 0.21811933562824667, 1.0252990115147431, 0.4458364308333144, 0.4458364308333144, 0.7698421419132718, 1.0253014010649544, 1.033688329950651, 0.5362737788539006, 0.5935783885253907, 0.08479691264648438, 0.25439073793945316, 0.7628217431696176, 0.31101371824504725, 0.15550685912252363, 0.4665205773675709, 1.025225157407064, 0.8719006659528398, 0.4454511918180438, 0.4454511918180438, 1.033671779185674, 0.9200749874580034, 0.5362739492443814, 0.22115122213800995, 0.33172683320701496, 0.4423024442760199, 0.5362738640491276, 0.762768857943141, 1.0252243155041503, 1.0252243155041503, 0.5354453830236626, 1.0252243155041503, 0.5362739066467511, 0.5362731398905619, 0.3160528748554968, 0.6321057497109936, 0.8087164854337585, 0.5446006328939096, 0.21784025315756386, 0.21784025315756386, 0.8087164854337585, 0.7542331128635615, 0.18855827821589038, 0.09427913910794519, 1.0252241284148018, 1.0336874339089066, 1.0252240348701531, 0.3126094286060633, 0.3126094286060633, 0.3126094286060633, 0.31685144088963596, 0.6337028817792719, 0.7864279382418061, 1.0252245961383013, 0.5362738640491276, 0.5362738214515107, 0.2642556836827746, 0.7927670510483238, 0.09792410917100866, 0.8533386656330755, 0.04196747535900371, 0.06117549493023734, 0.8717508027558821, 0.07646936866279667, 0.8022758613867104, 0.22663144479571087, 0.6798943343871326, 0.536273651061111, 0.13141506277172357, 0.13141506277172357, 0.7884903766303414, 0.7631323167036191, 0.6543815005180912, 0.21812716683936373, 0.21812716683936373, 0.5362737362562974, 1.0336878819295847, 0.769803302872033, 0.6594057660506769, 0.2198019220168923, 0.5594542081087721, 0.3846247680747808, 0.05244883201019738, 0.7712929396438308, 0.25709764654794365, 0.21835107002282886, 0.19105718626997525, 0.6004654425627793, 1.0192214717402681, 0.7628259569488461, 0.25428812028621217, 0.7628643608586365, 0.762768857943141, 1.0336875235130114], \"Term\": [\"abstract\", \"abstract\", \"aerosolart\", \"ai\", \"algun\", \"amazing\", \"amazing\", \"amazing\", \"appreciate\", \"art\", \"art\", \"art\", \"arte\", \"arte\", \"arte\", \"artist\", \"artist\", \"artist\", \"artistsoninstagram\", \"artlover\", \"artlover\", \"artsy\", \"artwork\", \"artwork\", \"back\", \"beautiful\", \"beautiful\", \"beautiful\", \"brilliant\", \"buen\", \"car\", \"chama\", \"cityofbrotherlylove\", \"collab\", \"color\", \"con\", \"contemporaryart\", \"contemporaryart\", \"cool\", \"cut\", \"cute\", \"detroitmural\", \"detroitusa\", \"direct\", \"dm\", \"dm\", \"dm\", \"draw\", \"draw\", \"dude\", \"estou\", \"fineart\", \"follow\", \"follow\", \"follow\", \"foodie\", \"fun\", \"go\", \"go\", \"good\", \"good\", \"gorgeous\", \"gymrockstar\", \"houstonartist\", \"isaacpelayo\", \"isso\", \"jjurbanart\", \"laart\", \"letter\", \"london\", \"londonart\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"make\", \"militarystroong\", \"modern\", \"momblogger\", \"mural\", \"mural\", \"mural\", \"muralart\", \"muralart\", \"muralart\", \"newandabstract\", \"nice\", \"nice\", \"nunca\", \"o\", \"paint\", \"paint\", \"paint\", \"paintbig\", \"painting\", \"painting\", \"painting\", \"pdx\", \"photo\", \"photo\", \"pic\", \"portland\", \"post\", \"project\", \"promote\", \"promote\", \"promote\", \"publicart\", \"que\", \"que\", \"que\", \"really\", \"romper\", \"send\", \"send\", \"series\", \"shoutout\", \"show\", \"streetart\", \"streetart\", \"streetart\", \"streetartdaily\", \"style\", \"tag\", \"take\", \"tasty\", \"thaicuisine\", \"toddlermom\", \"trashkitten\", \"travel\", \"travel\", \"uma\", \"urbanart\", \"urbanart\", \"urbanart\", \"vai\", \"virtuosoig\", \"virtuosoig\", \"virtuosoig\", \"visit\", \"vous\", \"walk\", \"wallart\", \"wallart\", \"wallart\", \"wele\", \"wele\", \"worldshot\", \"yesss\", \"\\u015bwi\\u0105t\", \"\\u05d7\\u05de\\u05d5\\u05d3\\u05d4\", \"\\u2728\", \"\\u2728\", \"\\u2764\", \"\\u2764\", \"\\u2764\", \"\\ufe0f\", \"\\ufe0f\", \"\\ufe0f\", \"\\ud83c\\udf40\", \"\\ud83d\\udc4c\", \"\\ud83d\\udc4c\", \"\\ud83d\\udc4d\", \"\\ud83d\\udc4f\", \"\\ud83d\\udc4f\", \"\\ud83d\\udc4f\", \"\\ud83d\\udc8e\", \"\\ud83d\\udc99\", \"\\ud83d\\udc99\", \"\\ud83d\\udc99\", \"\\ud83d\\udc9a\", \"\\ud83d\\udc9d\", \"\\ud83d\\udcaf\", \"\\ud83d\\udd1d\", \"\\ud83d\\udd1d\", \"\\ud83d\\udd25\", \"\\ud83d\\udd25\", \"\\ud83d\\udd25\", \"\\ud83d\\ude02\", \"\\ud83d\\ude02\", \"\\ud83d\\ude0d\", \"\\ud83d\\ude0d\", \"\\ud83d\\ude0d\", \"\\ud83d\\ude18\", \"\\ud83d\\ude1a\", \"\\ud83d\\ude2e\", \"\\ud83d\\ude2e\", \"\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\\ud83e\\udd0d\", \"\\ud83e\\udd93\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el848424740223480489464137224\", ldavis_el848424740223480489464137224_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el848424740223480489464137224\", ldavis_el848424740223480489464137224_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el848424740223480489464137224\", ldavis_el848424740223480489464137224_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1      0.016168 -0.106108       1        1  36.043798\n",
              "2     -0.107293  0.040084       2        1  33.962417\n",
              "0      0.091125  0.066023       3        1  29.993785, topic_info=        Term       Freq      Total Category  logprob  loglift\n",
              "47         ❤  71.000000  71.000000  Default  30.0000  30.0000\n",
              "48         ️  65.000000  65.000000  Default  29.0000  29.0000\n",
              "51         🔥  57.000000  57.000000  Default  28.0000  28.0000\n",
              "85         👏  15.000000  15.000000  Default  27.0000  27.0000\n",
              "50         😍  36.000000  36.000000  Default  26.0000  26.0000\n",
              "..       ...        ...        ...      ...      ...      ...\n",
              "47         ❤   3.232173  71.483928   Topic3  -5.2823  -1.8921\n",
              "16      love   2.209123  18.521688   Topic3  -5.6629  -0.9222\n",
              "72     paint   1.466896   7.217326   Topic3  -6.0723  -0.3892\n",
              "55      arte   1.455851   4.541130   Topic3  -6.0799   0.0666\n",
              "663  wallart   1.452596   3.198880   Topic3  -6.0821   0.4147\n",
              "\n",
              "[185 rows x 6 columns], token_table=      Topic      Freq        Term\n",
              "term                             \n",
              "302       1  0.507583    abstract\n",
              "302       2  0.507583    abstract\n",
              "284       1  1.025225  aerosolart\n",
              "238       2  0.516566          ai\n",
              "175       3  0.536274       algun\n",
              "...     ...       ...         ...\n",
              "229       1  0.762826           😚\n",
              "52        1  0.254288           😮\n",
              "52        2  0.762864           😮\n",
              "565       1  0.762769    🤍🤍🤍🤍🤍🤍🤍🤍\n",
              "274       2  1.033688           🦓\n",
              "\n",
              "[191 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}